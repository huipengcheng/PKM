---
tags: 📥️/📚️/🟥️
aliases:
type: book
status: 🟥️
created: 2022-05-05 15-55
updated: 2022-06-01 22-15
---

# Title: [[{ 2021-08 Java8 函数式编程]]

## Metadata
- `Topics:` [[Java]] [[Functional]]
- `Title:` [[{ 2021-08 Java8 函数式编程]]
- `Type:` [[{]]
- `Publish Date:` 
- `Reviewed Date:` [[2022-05-05]]

## Note

# 其他

-   Lambda 是一个行为。
    
-   TODO：Lambda 使用局部变量时为什么要 final。
    
-   for 遍历集合是外部迭代，因为要把集合元素取出来；而 Iterator 和 Stream 是内部迭代。
    
-   有一连串的中间操作的 Stream，但只会在集合内部执行一次迭代。
    
-   接口可以返回 Stream，而不是 List 等。通过 Stream 暴露集合的最大优点在于，它很好地封装了内部实现的数据结构。仅暴露一个 Stream 接口，用户在实际操作中无论如何使用，**都不会影响内部的 List 或 Set**。
    
-    String name = getUserName();  
     button.addActionListener(event -> System.out.println("hi " + name));
    
    name 在 lambad 表达式之前没有被修改过，所以它可以被认为是 final 的。这种变量叫 “既成事实上的 final“，也就是只给该变量赋值一次。 如果在 lambda 表达式之前多次给 name 赋值，那么编译就不会通过。
    
-    ActionEvent localEvent = null;  
     button.addActionListener(event -> {  
         localEvent = event;  
     });
    
    这段代码试图将 event 赋给一个局部变量，它无法通过编译，但绝非编写错误。这实际上是语言的设计者有意为之，用以鼓励用户使用 Lambda 表达式获取值而不是变量。获取值使用户更容易写出没有副作用的代码。
    
-    public interface Jukebox {  
         public default String rock() {   
             return "... all over the world!";  
         }   
     }  
     ​  
     public interface Carriage {  
         public default String rock() {   
             return "... from side to side";  
         }   
     }  
     ​  
     public class MusicalCarriage implements Carriage, Jukebox { }
    
    此时会编译器会报错，因为不明确应该继承哪个接口中的方法，应该像下面这样：
    
     public class MusicalCarriage implements Carriage, Jukebox {  
         @Override  
         public String rock() {  
             return Carriage.super.rock();    
         }  
     }
    
    > 使用增强的 super 语法：InterfaceName.super 指定继承自父接口的方法。
    

# 高级集合类和收集器

-   如果原集合是有序的，如 List，那么对应的 Stream 也是有序的；如果是无序的，如 Set，那么对应的 Stream 也是无序的。
    
-   如果一些操作在有序的流上开销更大，调用 `unordered` 方法消除这种顺序就能解决该问题。大多数操作都是在有序流上效率更高，比如 filter、map 和 reduce 等。
    
-   使用 toCollection，用定制的集合收集元素。
    
-   `SummaryStatistics`，`IntStream`。
    
-   Collectors 下的 averagingInt、summingInt 等。
    
-   Collectors.mapping
    
     public Map<Artist, List<String>> nameOfAlbums(Stream<Album> albums) { return   
         albums.collect(groupingBy(Album::getMainMusician,  
                                   mapping(Album::getName, toList())));  
     }
    
    第二个收集器用以收集最终结果的一个子集，这些收集器叫作下游收集器。
    
-   Map.compute
    

## 自定义收集器

格式化艺术家的姓名

 StringBuilder builder = new StringBuilder("[");   
 for (Artist artist : artists) {  
     if (builder.length() > 1)   
         builder.append(", ");  
     String name = artist.getName();  
     builder.append(name);  
 }  
 builder.append("]");  
 String result = builder.toString();

先使用 reduce 改造

StringBuilder reduced =  
    artists.stream()  
    .map(Artist::getName)  
    .reduce(new StringBuilder(), (builder, name) -> {  
        if (builder.length() > 0)  
            builder.append(", ");  
        builder.append(name);  
        return builder;  
    }, (left, right) -> left.append(right));  
reduced.insert(0, "[");  
reduced.append("]");  
String result = reduced.toString();

实现 StringCombiner（内部将操作代理给一个 StringBuilder 对象）

 String result =  
     artists.stream()  
     .map(Artist::getName)  
     .reduce(new StringCombiner(", ", "[", "]"),  
             StringCombiner::add,  
             StringCombiner::merge);  
     .toString();  
 ​  
 ​  
 public StringCombiner add(String element) {   
     if (areAtStart()) {  
         builder.append(prefix); }  
     else{  
         builder.append(delim);  
     }  
     builder.append(element);  
     return this;  
 }  
 ​  
 public StringCombiner merge(StringCombiner other) {   
     builder.append(other.builder);  
     return this;  
 }

自定义收集器

  String result =  
          artists.stream()  
                 .map(Artist::getName)  
                 .collect(new StringCollector(", ", "[", "]"));

一个收集器由四部分组成。首先是一个 Supplier，这是一个工厂方法，用来创建容器，在这个例子中，就是 StringCombiner。和 reduce 操作中的第一个参数类似，它是后续操作的初值。

收集器的 accumulator 的作用和 reduce 操作的第二个参数一样，它结合之前操作的结果 和当前值，生成并返回新的值。这一逻辑已经在 StringCombiners 的 add 方法中得以实现， 直接引用就好了

combiner 方法很像 reduce 操作的第三个方法。如果有两个容器，我们需要将其合并。同样，在前面的重构中我们已经实现了该功能，直接使用 StringCombiner.merge 方法就行了。

集器的 finisher 方法作用相同。我们已经将流中的值叠加入一个可变容器中，但这还不 是我们想要的最终结果。这里调用了 finisher 方法，以便进行转换。在我们想创建字符串 等不可变的值时特别有用，这里容器是可变的。

为了实现 finisher 方法，只需将该操作代理给已经实现的 toString 方法即可

 public class StringCollector implements Collector<String, StringCombiner, String> {  
     public Supplier<StringCombiner> supplier() {  
         return () -> new StringCombiner(delim, prefix, suffix);  
     }  
       
     public BiConsumer<StringCombiner, String> accumulator() {   
         return StringCombiner::add;  
 ​  
     }  
       
     public BinaryOperator<StringCombiner> combiner() {   
         return StringCombiner::merge;  
     }  
 ​  
     public Function<StringCombiner, String> finisher() {   
         return StringCombiner::toString;  
     }  
 }

收集器，还有一点一直没有提及，那就是特征。特征是一组描述收集器的对象，框架可以对其适当优化。characteristics 方法定义了特征。

     enum Characteristics {  
         /**  
          * Indicates that this collector is <em>concurrent</em>, meaning that  
          * the result container can support the accumulator function being  
          * called concurrently with the same result container from multiple  
          * threads.  
          *  
          * <p>If a {@code CONCURRENT} collector is not also {@code UNORDERED},  
          * then it should only be evaluated concurrently if applied to an  
          * unordered data source.  
          */  
         CONCURRENT,  
 ​  
         /**  
          * Indicates that the collection operation does not commit to preserving  
          * the encounter order of input elements.  (This might be true if the  
          * result container has no intrinsic order, such as a {@link Set}.)  
          */  
         UNORDERED,  
 ​  
         /**  
          * Indicates that the finisher function is the identity function and  
          * can be elided.  If set, it must be the case that an unchecked cast  
          * from A to R will succeed.  
          */  
         IDENTITY_FINISH  
     }

# 数据并行化

## 介绍

实现蒙特卡洛模拟法，掷两个骰子，统计每个种值出现的可能性。模拟投掷骰子的次数越多，得到的结果越准确。

 public Map<Integer, Double> parallelDiceRolls() {  
 ​  
     double fraction = 1.0 / N;  
 ​  
     return IntStream.range(0, N)   
         .parallel()  
         .mapToObj(twoDiceThrows())  
         .collect(groupingBy(side -> side, summingDouble(n -> fraction)));  
 }

collect 处使用 groupingBy 将点数一样的结果合并。

如果手动实现并行化蒙特卡洛模拟法，大多数代码都在处理调度和等待线程池中的某项任务完成：

 public class ManualDiceRolls {  
 ​  
     private static final int N = 100000000;  
     private final double fraction;  
     private final Map<Integer, Double> results;   
     private final int numberOfThreads;  
     private final ExecutorService executor;   
     private final int workPerThread;  
 ​  
     public static void main(String[] args) {   
         ManualDiceRolls roles = new ManualDiceRolls();   
         roles.simulateDiceRoles();  
     }  
 ​  
     public ManualDiceRolls() {  
         fraction = 1.0 / N;  
         results = new ConcurrentHashMap<>();  
         numberOfThreads = Runtime.getRuntime().availableProcessors();  
         executor = Executors.newFixedThreadPool(numberOfThreads);   
         workPerThread = N / numberOfThreads;  
     }  
 ​  
     public void simulateDiceRoles() {   
         List<Future<?>> futures = submitJobs();   
         awaitCompletion(futures);   
         printResults();  
     }  
 ​  
     private void printResults() {   
         results.entrySet()  
            .forEach(System.out::println);  
     }  
 ​  
     private List<Future<?>> submitJobs() {   
         List<Future<?>> futures = new ArrayList<>();   
         for (int i = 0; i < numberOfThreads; i++) {  
             futures.add(executor.submit(makeJob()));  
         }  
         return futures;   
     }  
 ​  
      
     private Runnable makeJob() {   
         return () -> {  
             ThreadLocalRandom random = ThreadLocalRandom.current();   
             for (int i = 0; i < workPerThread; i++) {  
                 int entry = twoDiceThrows(random);  
                 accumulateResult(entry);  
             }  
         };   
     }  
 ​  
     private void accumulateResult(int entry) {   
         results.compute(entry, (key, previous) ->  
                         previous == null ? fraction  
                         : previous + fraction  
                        );   
     }  
 ​  
     private int twoDiceThrows(ThreadLocalRandom random) {   
         int firstThrow = random.nextInt(1, 7);  
         int secondThrow = random.nextInt(1, 7);  
         return firstThrow + secondThrow;  
     }  
 ​  
     private void awaitCompletion(List<Future<?>> futures) {   
         futures.forEach((future) -> {  
             try { future.get();  
                 } catch (InterruptedException | ExecutionException e) {  
                 e.printStackTrace();  
             }  
         });  
         executor.shutdown();  
     }  
 }

## 限制

-   并行 reduce 的时候，必须保证初始值为组合函数的恒等值。拿恒等值和其他值做 reduce 操作时，其他值保持不变。比如，使用 reduce 操作求和，组合函数为 `(acc, element) -> acc + element`，则其初值必须为0，因为任何数字加 0，值不变。
    
-   reduce 操作的另一个限制是组合操作必须符合结合律。这意味着只要序列的值不变，组合操作的顺序不重要。
    
-   并行时，还要避免手动为数据结构加锁。因为流框架在需要的时候，自己处理同步操作。
    
-   `sequential` 将并行流转为串行。
    

## 性能

-   数据大小。将问题分解之后并行化处理，再将结果合并会带来额外的开销。因此只有数据足够大、每个数据处理管道花费的时间足够多时，并行化处理才有意义。
    
-   源数据结构。每个管道的操作都基于一些初始数据源，通常是集合。将不同的数据源分割相对容易，这里的开销影响了在管道中并行处理数据时到底能带来多少性能上的提升。
    
-   装箱。处理基本类型比处理装箱类型要快。
    
-   核的数量。只有一个核就完全没必要并行化。显然，拥有的核越多，获得潜在性能提升的幅度就越大。在实践中，核的数量不单指你的机器上有多少核，更是指**运行时**你的机器能使用多少核。这也就是说同时运行的其他进程，或者线程关联性（强制线程在某些核或 CPU 上运行）会影响性能。
    
-   单元处理开销。比如数据大小，这是一场并行执行花费时间和分解合并操作开销之间的战争。花在流中每个元素身上的时间越长，并行操作带来的性能提升越明显。
    

并发流使用的数据结构性能排行：

-   性能好 ArrayList、数组或 IntStream.range。这些数据结构支持随机读取，也就是说它们能轻而易举地被任意分解。
    
-   性能一般。HashSet、TreeSet，这些数据结构不易公平地被分解，但是大多数时候分解是可能的。
    
-   性能差。有些数据结构难于分解，比如，可能要花 _O_(_N_) 的时间复杂度来分解问题。其中包括 LinkedList，对半分解太难了。还有 Streams.iterate 和 BufferedReader.lines，它们 长度未知，因此很难预测该在哪里分解。
    

在将流分割成多个任务时，可以分成两种不同的操作：无状态的和有状态的。无状态操作整个过程中不必维护状态，有状态操作则有维护状态所需的开销和限制。无状态操作有更好的并行性能，包括 map、 filter 和 flatMap，有状态操作包括 sorted、distinct 和 limit。

## 并行化数组

`Arrays` 类中：

-   parallelPrefix：任意给定一个函数，计算数组的和
    
-   parallelSetAll：更新数组元素
    
-   parallelSort：并行化对数组元素排序
    

初始化数组：

 public static double[] parallelInitialize(int size) {   
     double[] values = new double[size];   
     Arrays.parallelSetAll(values, i -> i);  
     return values;  
 }

计算滑动窗口平均数

 public static double[] simpleMovingAverage(double[] values, int n) {   
     double[] sums = Arrays.copyOf(values, values.length);   
     Arrays.parallelPrefix(sums, Double::sum);  
     int start = n - 1;  
     return IntStream.range(start, sums.length)  
         .mapToDouble(i -> {  
             double prefix = i == start ? 0 : sums[i - n];  
             return (sums[i] - prefix) / n;  
         })  
         .toArray();   
 }

# 重构

 ThreadLocal<Album> thisAlbum = new ThreadLocal<Album> () {   
     @Override protected Album initialValue() {  
         return database.lookupCurrentAlbum();   
     }  
 };  
 ​  
 ThreadLocal<Album> thisAlbum = ThreadLocal.withInitial(() -> database.lookupCurrentAlbum());

实现几个方法来统计专辑内的一些信息：

 public long countRunningTime() {   
     long count = 0;  
     for (Album album : albums) {  
         for (Track track : album.getTrackList()) {  
             count += track.getLength();  
         }  
     }  
     return count;  
 }  
 ​  
 public long countMusicians() {   
     long count = 0;  
     for (Album album : albums) {  
         count += album.getMusicianList().size();  
     }  
     return count;   
 }  
 ​  
 public long countTracks() {   
     long count = 0;  
     for (Album album : albums) {  
         count += album.getTrackList().size();  
     }  
     return count;   
 }

使用 stream 第一次重构

 public long countRunningTime() {   
     return albums.stream()  
         .mapToLong(album -> album.getTracks()  
                    .mapToLong(track -> track.getLength())  
                    .sum())  
         .sum();  
 }  
 ​  
 public long countMusicians() {   
     return albums.stream()  
         .mapToLong(album -> album.getMusicians().count())  
         .sum();  
 }  
 ​  
 public long countTracks() {   
     return albums.stream()  
         .mapToLong(album -> album.getTracks().count())  
         .sum();  
 }

继续重构

 public long countFeature(ToLongFunction<Album> function) { return albums.stream()  
     .mapToLong(function)  
     .sum();  
 }  
 ​  
 public long countTracks() {  
     return countFeature(album -> album.getTracks().count());  
 }  
 ​  
 public long countRunningTime() {  
     return countFeature(album -> album.getTracks()  
                         .mapToLong(track -> track.getLength())  
                         .sum());  
 }  
 public long countMusicians() {  
     return countFeature(album -> album.getMusicians().count());  
 }

# 调试流

`peek` 方法可以查看每个值，同时能继续操作流。peek 可以输出值，也可以打日志。也可以在写一个空方体的 peak，并打上断点来逐个调试流中的元素。如果 debugger 不支持空方法体，那么就简单将值映射为本身。

# 使用 lambda 的设计模式

## 命令模式

### 以前

 public interface Editor {  
     public void save();   
     public void open();   
     public void close();  
 }  
 ​  
 public interface Action {  
     public void perform();   
 }  
 ​  
 public class Save implements Action {  
     private final Editor editor;   
     public Save(Editor editor) {  
         this.editor = editor;  
     }  
 ​  
     @Override  
     public void perform() {  
         editor.save();  
     }  
 }  
 ​  
 public class Open implements Action {  
     private final Editor editor;  
     public Open(Editor editor) {   
         this.editor = editor;  
     }  
 ​  
     @Override  
     public void perform() {  
         editor.open();  
     }  
 }

 public class Macro {  
     private final List<Action> actions;  
 ​  
     public Macro() {  
         actions = new ArrayList<>();  
     }  
 ​  
     public void record(Action action) {   
         actions.add(action);  
     }  
 ​  
     public void run() {   
         actions.forEach(Action::perform);  
     }  
 }

 Macro macro = new Macro();  
 macro.record(new Open(editor));   
 macro.record(new Save(editor));   
 macro.record(new Close(editor));   
 macro.run();

### 使用 Lambda

 Macro macro = new Macro();   
 macro.record(() -> editor.open());   
 macro.record(() -> editor.save());   
 macro.record(() -> editor.close());   
 macro.run();

 Macro macro = new Macro();   
 macro.record(editor::open);   
 macro.record(editor::save);   
 macro.record(editor::close); macro.run();

不再需要编写 Save、Open 等具体命令类。

## 策略模式

### 以前

 public interface CompressionStrategy {  
     public OutputStream compress(OutputStream data) throws IOException;  
 }  
 ​  
 public class GzipCompressionStrategy implements CompressionStrategy {  
     @Override  
     public OutputStream compress(OutputStream data) throws IOException {  
         return new GZIPOutputStream(data);   
     }  
 }  
 ​  
 public class ZipCompressionStrategy implements CompressionStrategy {  
     @Override  
     public OutputStream compress(OutputStream data) throws IOException {  
         return new ZipOutputStream(data);   
     }  
 }  
 ​  
 public class Compressor {  
     private final CompressionStrategy strategy;  
 ​  
     public Compressor(CompressionStrategy strategy) {   
         this.strategy = strategy;  
     }  
 ​  
     public void compress(Path inFile, File outFile) throws IOException {   
         try (OutputStream outStream = new FileOutputStream(outFile)) {  
             Files.copy(inFile, strategy.compress(outStream));  
         }  
     }   
 }

 Compressor gzipCompressor = new Compressor(new GzipCompressionStrategy());  
 gzipCompressor.compress(inFile, outFile);  
 ​  
 Compressor zipCompressor = new Compressor(new ZipCompressionStrategy()); zipCompressor.compress(inFile, outFile);

### 使用 Lambda

去掉具体的策略实现，使用一个方法实现算法。

Compressor gzipCompressor = new Compressor(GZIPOutputStream::new);  
gzipCompressor.compress(inFile, outFile);  
  
Compressor zipCompressor = new Compressor(ZipOutputStream::new);   
zipCompressor.compress(inFile, outFile);

## 观察者模式

### 以前

public interface LandingObserver {  
    public void observeLanding(String name);   
}  
  
public class Moon {  
    private final List<LandingObserver> observers = new ArrayList<>();  
    public void land(String name) {  
        for (LandingObserver observer : observers) {  
            observer.observeLanding(name);  
        }  
    }  
  
    public void startSpying(LandingObserver observer) {   
        observers.add(observer);  
    }   
}  
  
public class Aliens implements LandingObserver {  
    @Override  
    public void observeLanding(String name) {  
        if (name.contains("Apollo")) {  
            System.out.println("They're distracted, lets invade earth!");  
        }   
    }  
}  
  
  
public class Nasa implements LandingObserver {   
    @Override  
  
    public void observeLanding(String name) {   
        if (name.contains("Apollo")) {  
            System.out.println("We made it!");  
        }  
    }   
}

Moon moon = new Moon(); moon.startSpying(new Nasa());   
moon.startSpying(new Aliens());  
     
moon.land("An asteroid");  
moon.land("Apollo 11");

### 使用 Lambda

Moon moon = new Moon();  
moon.startSpying(name -> {  
    if (name.contains("Apollo"))  
        System.out.println("We made it!");  
});  
  
moon.startSpying(name -> {  
    if (name.contains("Apollo"))  
        System.out.println("They're distracted, lets invade earth!");  
});  
  
moon.land("An asteroid");  
moon.land("Apollo 11");

## 例外

无论使用观察者模式或策略模式，实现时采用 Lambda 表达式还是传统的类，取决于策略和观察者代码的复杂度。如果过于复杂，采用 Lambda 反而会大大降低代码的可读性。

# 使用 Lambda 的 SOLID 原则

Single responsibility、Open/closed、Liskov substitution、Interface segregation 和 Dependency inversion。

## 单一指责原则

 public long countPrimes(int upTo) {   
     long tally = 0;  
     for(int i = 1; i < upTo; i++){   
         boolean isPrime = true;   
         for(int j = 2; j < i; j++){  
             if(i%j==0){   
                 isPrime = false;  
             }   
         }  
         if (isPrime) {  
             tally++;   
         }  
     }  
     return tally;   
 }

 public long countPrimes(int upTo) {   
     long tally = 0;  
     for(int i = 1; i < upTo; i++){   
         if (isPrime(i)) {  
             tally++;   
         }  
     }  
     return tally;   
 }  
 ​  
 private boolean isPrime(int number) {   
     for(int i = 2; i < number; i++){  
         if(number % i == 0){   
             return false;  
         }   
     }  
     return true;   
 }

public long countPrimes(int upTo) {   
    return IntStream.range(1, upTo)  
        // .parallel()  
        .filter(this::isPrime) .count();  
}  
  
private boolean isPrime(int number) {   
    return IntStream.range(2, number)  
        .allMatch(x -> (number % x) != 0);  
}

## 开闭原则

 class MetricDataGraph {  
     public void updateUserTime(int value);   
     public void updateSystemTime(int value);   
     public void updateIoTime(int value);  
 }

上面的类用来记录各项系统时间，但如果要添加新的时间点，就要修改该类。

引入抽象解决这个问题：

 class MetricDataGraph {  
     public void addTimeSeries(TimeSeries values);   
 }

每项具体指标现在可以实现 TimeSeries 接口，在需要时能直接插入。比如，现在有：UserTimeSeries、SystemTimeSeries 和 IoTimeSeries。如果要添加新的，则可增加一个新的实现了 TimeSeries 接口的类。这样，就扩展了 MetricDataGraph 类，但并没有修改它。

>  class MetricDataGraph {  
>   public void updateTimeSerie(TimeSerieEnum timeSerie,int values);   
>  ​  
>   enum TimeSerieEnum {  
>       USER_TIME,  
>       ...  
>   }  
>  }
> 
> 这样也符合开闭原则吧？

ThreadLocal 也符合开闭原则：

 ThreadLocal<DateFormat> localFormatter = ThreadLocal.withInitial(() -> new SimpleDateFormat());   
 ​  
 DateFormat formatter = localFormatter.get();

## 依赖反转原则

解析文件中的标题：

 public List<String> findHeadings(Reader input) {  
     try (BufferedReader reader = new BufferedReader(input)) {  
         return reader.lines()  
             .filter(line -> line.endsWith(":"))  
             .map(line -> line.substring(0, line.length() - 1))  
             .collect(toList());   
     }   
     catch (IOException e) {  
         throw new HeadingLookupException(e);   
     }  
 }

剥离了文件处理功能，让解析标题依赖 Stream<String>。

 public List<String> findHeadings(Reader input) {   
     return withLinesOf(input,  
                        lines -> lines.filter(line -> line.endsWith(":"))  
                        .map(line -> line.substring(0, line.length()-1))  
                        .collect(toList()),  
                        HeadingLookupException::new);  
 }  
 ​  
 private <T> T withLinesOf(Reader input, Function<Stream<String>, T> handler,  
                                Function<IOException, RuntimeException> error) {  
     try (BufferedReader reader = new BufferedReader(input)) {   
         return handler.apply(reader.lines());  
     } catch (IOException e) {   
         throw error.apply(e);  
     }   
 }

# 第八、九章要看一下
